{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d224ad6-cc67-4a76-b0fa-f7aa2624eceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature selection by SelectKBest method...\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d4d1b32-d3de-45e1-a774-e4e2eb0a9172",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_k_best(indep, dep, k):\n",
    "    \n",
    "    from sklearn.feature_selection import SelectKBest, chi2\n",
    "    skb=SelectKBest(score_func=chi2, k=3)\n",
    "    \n",
    "    # fit the selectkbest object to the data\n",
    "    skb_fit = skb.fit(indep, dep)\n",
    "    \n",
    "    # trasform the data to the Select top  K features\n",
    "    x_new = skb_fit.transform(indep)\n",
    "    \n",
    "    # Get the names of the selected features...\n",
    "    selected_features = indep.columns[skb.get_support()]\n",
    "    \n",
    "    return selected_features, x_new\n",
    "\n",
    "def standard_scalar(xtrain, xtest):\n",
    "    ### standard scalar\n",
    "\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    scx = StandardScaler()\n",
    "    x_train_scaled = scx.fit_transform(xtrain)\n",
    "    x_test_scaled = scx.fit_transform (xtest)\n",
    "    return x_train_scaled, x_test_scaled\n",
    "\n",
    "def metrices(ytest, y_pred):\n",
    "    # making the confusion matrix, classification_report, accuracy_score\n",
    "\n",
    "    from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "    cm = confusion_matrix(ytest, y_pred)\n",
    "    clf_report = classification_report(ytest, y_pred)\n",
    "    acc_score = accuracy_score(ytest, y_pred)\n",
    "    return cm , clf_report, acc_score\n",
    "    \n",
    "#### 1. logistic regression    \n",
    "def logistic(x_train_scaled, x_test_scaled, ytrain, ytest):\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    classifier =LogisticRegression(random_state=0)\n",
    "    model =classifier.fit(x_train_scaled,ytrain)\n",
    "    y_pred = model.predict(x_test_scaled)\n",
    "\n",
    "    cm,clf_report, acc_score = metrices(ytest, y_pred)\n",
    "    return cm , clf_report, acc_score  \n",
    "    \n",
    "### 2. SVM_linear\n",
    "\n",
    "def svm_linear(x_train_scaled, x_test_scaled, ytrain, ytest): \n",
    "    from sklearn.svm import SVC\n",
    "    classifier = SVC(kernel=\"linear\", random_state=0)\n",
    "    model =classifier.fit(x_train_scaled,ytrain)\n",
    "    y_pred = model.predict(x_test_scaled)\n",
    "\n",
    "    cm,clf_report, acc_score = metrices(ytest, y_pred)\n",
    "    return cm , clf_report, acc_score \n",
    "\n",
    "### 3. SVM_linear\n",
    "def svm_nonLinear(x_train_scaled, x_test_scaled, ytrain, ytest):\n",
    "    from sklearn.svm import SVC\n",
    "    classifier= SVC(kernel='rbf', random_state=0)\n",
    "    model =classifier.fit(x_train_scaled,ytrain)\n",
    "    y_pred = model.predict(x_test_scaled)\n",
    "\n",
    "    cm,clf_report, acc_score = metrices(ytest, y_pred)\n",
    "    return cm , clf_report, acc_score\n",
    "    \n",
    "### 4. Decision Tree\n",
    "def decision(x_train_scaled, x_test_scaled, ytrain, ytest):\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    classifier = DecisionTreeClassifier(criterion='entropy', random_state=0)\n",
    "    model =classifier.fit(x_train_scaled,ytrain)\n",
    "    y_pred = model.predict(x_test_scaled)\n",
    "\n",
    "    cm,clf_report, acc_score = metrices(ytest, y_pred)\n",
    "    return cm , clf_report, acc_score\n",
    "\n",
    "### 5. RandomForest\n",
    "def random(x_train_scaled, x_test_scaled, ytrain, ytest):\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    classifier = RandomForestClassifier(n_estimators=10, criterion='entropy', random_state=0)\n",
    "    model =classifier.fit(x_train_scaled,ytrain)\n",
    "    y_pred = model.predict(x_test_scaled)\n",
    "    \n",
    "    cm,clf_report, acc_score = metrices(ytest, y_pred)\n",
    "    return cm , clf_report, acc_score\n",
    "\n",
    "## 6. KNN (KNearestNeighbours)\n",
    "\n",
    "##Power parameter for the Minkowski metric. When p = 1, \n",
    "#####   this is equivalent to using manhattan_distance (l1), and euclidean_distance (l2) for p = 2.\n",
    "######    For arbitrary p, minkowski_distance (l_p) is used.\n",
    "## Metric to use for distance computation. Default is \"minkowski\", which\n",
    "##### results in the standard Euclidean distance when p = 2. \n",
    "def knn(x_train_scaled, x_test_scaled, ytrain, ytest):\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    classifier = KNeighborsClassifier(n_neighbors=5,metric='minkowski', p=2 )\n",
    "    model =classifier.fit(x_train_scaled,ytrain)\n",
    "    y_pred = model.predict(x_test_scaled)\n",
    "\n",
    "    cm,clf_report, acc_score = metrices(ytest, y_pred)\n",
    "    return cm , clf_report, acc_score\n",
    "\n",
    "### 7. Naive Bayes\n",
    "def naive(x_train_scaled, x_test_scaled, ytrain, ytest):\n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "    classifier = GaussianNB()\n",
    "    model =classifier.fit(x_train_scaled,ytrain)\n",
    "    y_pred = model.predict(x_test_scaled)\n",
    "    \n",
    "    cm,clf_report, acc_score = metrices(ytest, y_pred)\n",
    "    return cm , clf_report, acc_score\n",
    "\n",
    "\n",
    "#### display the accuracy in a table\n",
    "\n",
    "def view_acc_score(acc_logistic,acc_svmlinear,acc_svm_nonlinear,acc_decision,acc_random,acc_knn,acc_naive):\n",
    "\n",
    "    table= pd.DataFrame(index=[\"chi square\"], columns=[\"Logistic\",\"svmlinear\",\"svm_nonlinear\",\"decision\",\"random\",\"knn\",\"naive\"])\n",
    "    # Loop through each index label and assign values from the lists to the corresponding row\n",
    "    for i, label in enumerate(table.index):\n",
    "        table.loc[label] = [\n",
    "            acc_logistic[i], \n",
    "            acc_svmlinear[i], \n",
    "            acc_svm_nonlinear[i], \n",
    "            acc_decision[i], \n",
    "            acc_random[i], \n",
    "            acc_knn[i], \n",
    "            acc_naive[i]\n",
    "    ]\n",
    "\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aca3723d-0254-4ac5-bc7c-f5267e56cbf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=pd.read_csv(\"prep_ds.csv\")\n",
    "#dataset\n",
    "\n",
    "### separation of indep and dep vars\n",
    "\n",
    "indep = dataset.drop(\"HeartDisease\", axis=1)\n",
    "dep = dataset[\"HeartDisease\"]\n",
    "\n",
    "# Applying the SelectKbest...\n",
    "selected_features, x_new = select_k_best(indep, dep, 5)\n",
    "\n",
    "### Separation of Training and Test dataset...\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(x_new, dep, test_size=0.30, random_state=1)\n",
    "\n",
    "# Standard scalar\n",
    "x_train_scaled, x_test_scaled = standard_scalar(xtrain, xtest)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e587620-50a0-4a95-b95f-81330a91f3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_logistic= []\n",
    "acc_svmlinear = []\n",
    "acc_svm_nonlinear = []\n",
    "acc_decision = []\n",
    "acc_random = []\n",
    "acc_knn = []\n",
    "acc_naive = []\n",
    "\n",
    "\n",
    "cm ,clf_report,acc_score= logistic(x_train_scaled, x_test_scaled, ytrain, ytest)\n",
    "acc_logistic.append(acc_score)\n",
    "\n",
    "cm ,clf_report,acc_score= svm_linear(x_train_scaled, x_test_scaled, ytrain, ytest)\n",
    "acc_svmlinear.append(acc_score)\n",
    "\n",
    "cm ,clf_report,acc_score= svm_nonLinear(x_train_scaled, x_test_scaled, ytrain, ytest)\n",
    "acc_svm_nonlinear.append(acc_score)\n",
    "\n",
    "cm ,clf_report,acc_score= decision(x_train_scaled, x_test_scaled, ytrain, ytest)\n",
    "acc_decision.append(acc_score)\n",
    "\n",
    "cm ,clf_report,acc_score= random(x_train_scaled, x_test_scaled, ytrain, ytest)\n",
    "acc_random.append(acc_score)\n",
    "\n",
    "cm ,clf_report,acc_score= knn(x_train_scaled, x_test_scaled, ytrain, ytest)\n",
    "acc_knn.append(acc_score)\n",
    "\n",
    "cm ,clf_report,acc_score= naive(x_train_scaled, x_test_scaled, ytrain, ytest)\n",
    "acc_naive.append(acc_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24dbd989-87b2-4ab7-8fcd-e84da49da585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features:  Index(['MaxHR', 'ST_Slope_Flat', 'ST_Slope_Up'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#### selected features:\n",
    "\n",
    "print (\"Selected Features: \", selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9df837d2-827d-4f30-8ecf-3f1bed5de042",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MaxHR</th>\n",
       "      <th>ST_Slope_Flat</th>\n",
       "      <th>ST_Slope_Up</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>156</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>156</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>122</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>913</th>\n",
       "      <td>132</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>914</th>\n",
       "      <td>141</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>915</th>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>916</th>\n",
       "      <td>156</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>917</th>\n",
       "      <td>156</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>918 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     MaxHR  ST_Slope_Flat  ST_Slope_Up\n",
       "0      156              0            1\n",
       "1      156              1            0\n",
       "2      120              0            1\n",
       "3      120              1            0\n",
       "4      122              0            1\n",
       "..     ...            ...          ...\n",
       "913    132              1            0\n",
       "914    141              1            0\n",
       "915    120              1            0\n",
       "916    156              1            0\n",
       "917    156              0            1\n",
       "\n",
       "[918 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[selected_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f1660c7-30ac-42bb-b60b-da18654bb6da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Logistic</th>\n",
       "      <th>svmlinear</th>\n",
       "      <th>svm_nonlinear</th>\n",
       "      <th>decision</th>\n",
       "      <th>random</th>\n",
       "      <th>knn</th>\n",
       "      <th>naive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>chi square</th>\n",
       "      <td>0.82971</td>\n",
       "      <td>0.82971</td>\n",
       "      <td>0.818841</td>\n",
       "      <td>0.717391</td>\n",
       "      <td>0.757246</td>\n",
       "      <td>0.797101</td>\n",
       "      <td>0.811594</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Logistic svmlinear svm_nonlinear  decision    random       knn  \\\n",
       "chi square  0.82971   0.82971      0.818841  0.717391  0.757246  0.797101   \n",
       "\n",
       "               naive  \n",
       "chi square  0.811594  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Disply the accuracy score in a table\n",
    "\n",
    "table =view_acc_score(acc_logistic,acc_svmlinear,acc_svm_nonlinear,acc_decision,acc_random,acc_knn,acc_naive)\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09593ea6-4ef4-4b6a-9859-7960bd1cb90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Conclusion: Accuracy score for LogisticRegression and SVMLinear is high than the other ones...\n",
    "###################so we will save any one of these two models for deployment\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b240259f-366d-4bf5-8c84-6b52555ed262",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
